{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Naive model on the same tickers used for my sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>volatility</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>len</th>\n",
       "      <th>rmse_standard</th>\n",
       "      <th>rmse_tuned</th>\n",
       "      <th>winsorized_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADYEY</td>\n",
       "      <td>Medium</td>\n",
       "      <td>16.389898</td>\n",
       "      <td>1347</td>\n",
       "      <td>5.087750</td>\n",
       "      <td>7.321585</td>\n",
       "      <td>0.397179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMM</td>\n",
       "      <td>Medium</td>\n",
       "      <td>63.829555</td>\n",
       "      <td>4339</td>\n",
       "      <td>23.137863</td>\n",
       "      <td>18.612367</td>\n",
       "      <td>0.373358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARK</td>\n",
       "      <td>High</td>\n",
       "      <td>214.811263</td>\n",
       "      <td>5455</td>\n",
       "      <td>10.280774</td>\n",
       "      <td>4.454470</td>\n",
       "      <td>0.273877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIGI</td>\n",
       "      <td>Low</td>\n",
       "      <td>63.282331</td>\n",
       "      <td>2251</td>\n",
       "      <td>12.586773</td>\n",
       "      <td>3.847514</td>\n",
       "      <td>0.545980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GDRX</td>\n",
       "      <td>Medium-High</td>\n",
       "      <td>17.561466</td>\n",
       "      <td>1102</td>\n",
       "      <td>2.904431</td>\n",
       "      <td>1.844597</td>\n",
       "      <td>0.259528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker   volatility   avg_price   len  rmse_standard  rmse_tuned  \\\n",
       "0  ADYEY       Medium   16.389898  1347       5.087750    7.321585   \n",
       "1    NMM       Medium   63.829555  4339      23.137863   18.612367   \n",
       "2   MARK         High  214.811263  5455      10.280774    4.454470   \n",
       "3   VIGI          Low   63.282331  2251      12.586773    3.847514   \n",
       "4   GDRX  Medium-High   17.561466  1102       2.904431    1.844597   \n",
       "\n",
       "   winsorized_pct  \n",
       "0        0.397179  \n",
       "1        0.373358  \n",
       "2        0.273877  \n",
       "3        0.545980  \n",
       "4        0.259528  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses_df = pd.read_csv('combined_model_rmse.csv')\n",
    "rmses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADYEY',\n",
       " 'NMM',\n",
       " 'MARK',\n",
       " 'VIGI',\n",
       " 'GDRX',\n",
       " 'FTGS',\n",
       " 'GOVX',\n",
       " 'DFEM',\n",
       " 'WABC',\n",
       " 'SDA',\n",
       " 'AAOI',\n",
       " 'CRGY',\n",
       " 'JHMD',\n",
       " 'XLK',\n",
       " 'FTLS',\n",
       " 'CL',\n",
       " 'MPWR',\n",
       " 'THQ',\n",
       " 'EFX',\n",
       " 'FFTY',\n",
       " 'EFSC',\n",
       " 'WDC',\n",
       " 'JG',\n",
       " 'MYRG',\n",
       " 'DBC',\n",
       " 'VFLO',\n",
       " 'CCL',\n",
       " 'SPTN',\n",
       " 'OILD',\n",
       " 'REZI',\n",
       " 'WBD',\n",
       " 'BILS',\n",
       " 'GMPR',\n",
       " 'AHEXY',\n",
       " 'UDMY',\n",
       " 'ARTY',\n",
       " 'GFAI',\n",
       " 'FPEI',\n",
       " 'VINC',\n",
       " 'VERV',\n",
       " 'HLVX',\n",
       " 'CLDT',\n",
       " 'RELI',\n",
       " 'GXO',\n",
       " 'AZTA',\n",
       " 'FBEC',\n",
       " 'ILPT',\n",
       " 'WTW',\n",
       " 'CDP',\n",
       " 'CNK',\n",
       " 'PFS',\n",
       " 'TPC',\n",
       " 'TCHP',\n",
       " 'VYX',\n",
       " 'GWW',\n",
       " 'TDTT',\n",
       " 'WB',\n",
       " 'TMO',\n",
       " 'CVLT',\n",
       " 'USIO',\n",
       " 'CNMD',\n",
       " 'SGBX',\n",
       " 'MUST',\n",
       " 'SUI',\n",
       " 'QNCX',\n",
       " 'FOXA',\n",
       " 'XOM',\n",
       " 'INVA',\n",
       " 'AIXI',\n",
       " 'CMA',\n",
       " 'WU',\n",
       " 'EFV',\n",
       " 'HIGH',\n",
       " 'WEX',\n",
       " 'DEO',\n",
       " 'ANGO',\n",
       " 'HOMB',\n",
       " 'DCOM',\n",
       " 'SAH',\n",
       " 'NEAR',\n",
       " 'CALX',\n",
       " 'OEC',\n",
       " 'IVOL',\n",
       " 'FCPT',\n",
       " 'SNCY',\n",
       " 'BLV',\n",
       " 'XLU',\n",
       " 'STIP',\n",
       " 'PGF',\n",
       " 'WJRYY',\n",
       " 'GMNI',\n",
       " 'STRL',\n",
       " 'FAF',\n",
       " 'BSY',\n",
       " 'ETNB',\n",
       " 'HPE',\n",
       " 'FTDR',\n",
       " 'DY',\n",
       " 'MUB',\n",
       " 'VGIT',\n",
       " 'SGRY',\n",
       " 'SE',\n",
       " 'XLP',\n",
       " 'ARMN',\n",
       " 'MRNA',\n",
       " 'APP',\n",
       " 'RDCM',\n",
       " 'ENGN',\n",
       " 'AOR',\n",
       " 'PED',\n",
       " 'BBW',\n",
       " 'CYTK',\n",
       " 'APM',\n",
       " 'GDLC',\n",
       " 'IGLB',\n",
       " 'ACON',\n",
       " 'BLEG',\n",
       " 'MNMD',\n",
       " 'SPLB',\n",
       " 'PDPR',\n",
       " 'IBMP',\n",
       " 'RXST',\n",
       " 'RELY',\n",
       " 'QLTA',\n",
       " 'USHY',\n",
       " 'MOAT',\n",
       " 'TNDM',\n",
       " 'CGMU',\n",
       " 'GOGO',\n",
       " 'HRTX',\n",
       " 'VYM',\n",
       " 'CGSD',\n",
       " 'CHWY',\n",
       " 'MPNGY',\n",
       " 'GTE',\n",
       " 'RPTX',\n",
       " 'DAR',\n",
       " 'BOOM',\n",
       " 'ENFY',\n",
       " 'GPRE',\n",
       " 'EXPI',\n",
       " 'PLCE',\n",
       " 'RDN',\n",
       " 'FLGT',\n",
       " 'OPRT',\n",
       " 'TWI',\n",
       " 'EVER',\n",
       " 'MRUS',\n",
       " 'WRBY',\n",
       " 'CWH']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = rmses_df['ticker'].tolist()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ticker):\n",
    "    \"\"\"\n",
    "    Downloads historical market data for a given ticker symbol.\n",
    "\n",
    "    Parameters:\n",
    "    ticker (str): The ticker symbol of the stock to download data for.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the historical market data for the specified ticker.\n",
    "    \"\"\"\n",
    "    data = yf.download(ticker, period='max') # returns relevant data in df\n",
    "    data.reset_index(inplace=True) # reset multindex, output is index list of tuples\n",
    "    cols = list(data.columns) # convert index to list\n",
    "    # cols[0] = ('Date', '') \n",
    "    # cols = [i[0] for i in cols] # return first element of cols tuples\n",
    "    # data.columns = cols # set as column names\n",
    "    data['Date'] = pd.to_datetime(data['Date']).dt.date\n",
    "    data.Date = data.Date.astype('datetime64[ns]')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = load_data('AAPL')\n",
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volatility(data):\n",
    "    volatility = data.daily_returns.std() * np.sqrt(252)\n",
    "    if volatility < 0.2:\n",
    "        category = \"Low\"\n",
    "        percentiles=(0.15, 0.85)\n",
    "    elif volatility < 0.4:\n",
    "        category = \"Medium-Low\"\n",
    "        percentiles=(0.1, 0.9)\n",
    "    elif volatility < 0.6:\n",
    "        category = \"Medium\"\n",
    "        percentiles=(0.1, 0.9)\n",
    "    elif volatility < 0.8:\n",
    "        category = \"Medium-High\"\n",
    "        percentiles=(0.05, 0.95)\n",
    "    else:\n",
    "        category = \"High\"\n",
    "        percentiles=(0.05, 0.95)\n",
    "    return category, volatility, percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_params(data, volatility):\n",
    "    if len(data)/365 < 8:\n",
    "        period_unit = int(len(data)/4)\n",
    "        forecast_period = period_unit\n",
    "        train_period = len(data)\n",
    "    else:\n",
    "        period_unit = 365\n",
    "        forecast_period = period_unit\n",
    "        train_period = forecast_period * 4 if volatility < 0.6 else forecast_period * 8\n",
    "    return train_period, period_unit, forecast_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_func = lambda model_name, train_period, period_unit, forecast_period: cross_validation(model_name, \n",
    "                                              initial=f'{train_period} days', \n",
    "                                              period=f'{period_unit} days', \n",
    "                                              horizon=f'{forecast_period} days', \n",
    "                                              parallel=\"processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast(history):\n",
    "    \"\"\"\n",
    "    Performs a naive forecast using the last value in the history.\n",
    "\n",
    "    Parameters:\n",
    "    history (pd.Series): Time series data to use as history.\n",
    "\n",
    "    Returns:\n",
    "    float: The naive forecast (last value of history).\n",
    "    \"\"\"\n",
    "    return history.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_cross_validation(data, initial, period, horizon):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for a naive forecasting model.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Time series data with 'Date' and 'Close' columns.\n",
    "    initial (int): Initial training period length in days.\n",
    "    period (int): Period between cutoffs in days.\n",
    "    horizon (int): Forecast horizon in days.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing actual values, forecasts, and cutoffs.\n",
    "    \"\"\"\n",
    "    initial_date = data['Date'].iloc[0]\n",
    "    cutoffs = pd.to_datetime([initial_date + pd.Timedelta(days=initial + i * period)\n",
    "                               for i in range(1 + (len(data) - initial - horizon) // period)])\n",
    "\n",
    "    periods_list = []\n",
    "    for cutoff in cutoffs:\n",
    "        train_df = data[data['Date'] <= cutoff].copy()\n",
    "        test_df = data[(data['Date'] > cutoff) & (data['Date'] <= cutoff + pd.Timedelta(days=horizon))].copy()\n",
    "\n",
    "        # if len(test_df) == 0: # Skip if no data in the horizon\n",
    "        #     continue\n",
    "\n",
    "        history = train_df['Close']\n",
    "        forecasts = [naive_forecast(history)] * len(test_df) # Naive forecast for all points in horizon\n",
    "\n",
    "        test_df['forecast'] = forecasts\n",
    "        test_df['cutoff'] = cutoff.date() # Store cutoff date\n",
    "\n",
    "        periods_list.append(test_df)\n",
    "\n",
    "    df_cv = pd.concat(periods_list).reset_index(drop=True)\n",
    "    return df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(cv_results):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from cross-validation results DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    cv_results (pd.DataFrame): DataFrame from naive_cross_validation.\n",
    "\n",
    "    Returns:\n",
    "    float: RMSE value.\n",
    "    \"\"\"\n",
    "    if cv_results.empty:\n",
    "        return np.nan  # Return NaN if no cross-validation results\n",
    "\n",
    "    return np.sqrt(mean_squared_error(cv_results['Close'], cv_results['forecast']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_rmse_for_tickers(tickers):\n",
    "    \"\"\"\n",
    "    Calculates naive model RMSE for a list of stock tickers.\n",
    "\n",
    "    Parameters:\n",
    "    tickers (list): List of stock ticker symbols.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with ticker symbols and their naive model RMSEs.\n",
    "    \"\"\"\n",
    "    naive_rmse_results = []\n",
    "    for ticker in tickers:\n",
    "        data = load_data(ticker)\n",
    "        data['daily_returns'] = data.Close.pct_change()\n",
    "        category, volatility, percentiles = get_volatility(data)\n",
    "        train_period, period_unit, forecast_period = get_period_params(data, volatility)\n",
    "\n",
    "        initial_days = train_period\n",
    "        period_days = period_unit\n",
    "        horizon_days = forecast_period\n",
    "\n",
    "        cv_results_naive = naive_cross_validation(\n",
    "            data[['Date', 'Close']], # Ensure only Date and Close are passed\n",
    "            initial=initial_days,\n",
    "            period=period_days,\n",
    "            horizon=horizon_days\n",
    "        )\n",
    "        rmse_naive = calculate_rmse(cv_results_naive)\n",
    "        naive_rmse_results.append({'Ticker': ticker, 'Naive_RMSE': rmse_naive})\n",
    "        print(f\"Naive RMSE for {ticker}: {rmse_naive:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(naive_rmse_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m naive_rmse_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_naive_rmse_for_tickers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m naive_rmse_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m, in \u001b[0;36mget_naive_rmse_for_tickers\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m     19\u001b[0m period_days \u001b[38;5;241m=\u001b[39m period_unit\n\u001b[1;32m     20\u001b[0m horizon_days \u001b[38;5;241m=\u001b[39m forecast_period\n\u001b[0;32m---> 22\u001b[0m cv_results_naive \u001b[38;5;241m=\u001b[39m \u001b[43mnaive_cross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Ensure only Date and Close are passed\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_days\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod_days\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhorizon_days\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m rmse_naive \u001b[38;5;241m=\u001b[39m calculate_rmse(cv_results_naive)\n\u001b[1;32m     29\u001b[0m naive_rmse_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m: ticker, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaive_RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: rmse_naive})\n",
      "Cell \u001b[0;32mIn[10], line 34\u001b[0m, in \u001b[0;36mnaive_cross_validation\u001b[0;34m(data, initial, period, horizon)\u001b[0m\n\u001b[1;32m     30\u001b[0m     test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcutoff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cutoff\u001b[38;5;241m.\u001b[39mdate() \u001b[38;5;66;03m# Store cutoff date\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     periods_list\u001b[38;5;241m.\u001b[39mappend(test_df)\n\u001b[0;32m---> 34\u001b[0m df_cv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiods_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_cv\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "naive_rmse_df = get_naive_rmse_for_tickers(tickers)\n",
    "naive_rmse_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
